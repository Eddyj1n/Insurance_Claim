{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom objective function: Adjusted R2 score\n",
    "def adjusted_r2(y_true, y_pred, n_features):\n",
    "    n_samples = len(y_true)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    adjusted_r2 = 1 - (1 - r2) * (n_samples - 1) / (n_samples - n_features - 1)\n",
    "    return adjusted_r2\n",
    "\n",
    "# Define the custom scoring function\n",
    "def custom_scoring(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return adjusted_r2(y, y_pred, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data set\n",
    "df = pd.read_csv(\"data/data.csv\", parse_dates=['DateTimeOfAccident', 'DateReported'])\n",
    "\n",
    "# Copy original data frame\n",
    "df_engineer = df.copy()\n",
    "\n",
    "# Dummy encode marital status and gender\n",
    "df_engineer['MaritalStatus'] = df_engineer['MaritalStatus'].apply(lambda x: 0 if x == 'M' else 1)\n",
    "df_engineer['Gender'] = df_engineer['Gender'].apply(lambda x: 0 if x == 'M' else 1)\n",
    "\n",
    "# Create feature of time since report\n",
    "df_engineer['time_to_report'] = df_engineer['DateTimeOfAccident'] - df_engineer['DateReported']\n",
    "\n",
    "# Create time since first time point in data to proxy for inflation\n",
    "df_engineer['trend'] = df_engineer['DateTimeOfAccident'] - df_engineer['DateTimeOfAccident'].min()\n",
    "\n",
    "# Create Target: Claim complexity (absolute difference)\n",
    "df_engineer['claim_complexity'] = abs(df_engineer['UltimateIncurredClaimCost'] - df_engineer['InitialIncurredClaimsCost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gg/7_dfg0x950bcs4sn280vzt900000gn/T/ipykernel_72808/943647475.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['trend'] = X['trend'] / pd.Timedelta(hours=1)\n",
      "/var/folders/gg/7_dfg0x950bcs4sn280vzt900000gn/T/ipykernel_72808/943647475.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['time_to_report'] = X['time_to_report'] / pd.Timedelta(hours=1)\n"
     ]
    }
   ],
   "source": [
    "# Declare target and feature set\n",
    "y = df_engineer['claim_complexity']\n",
    "X = df_engineer[['InitialIncurredClaimsCost', 'trend', 'Gender', 'time_to_report', 'MaritalStatus', 'Age',\n",
    "                 'DependentChildren', 'DependentsOther', 'WeeklyWages', 'HoursWorkedPerWeek'] + \n",
    "                 [f'ClaimDescriptionKeyword_{i}' for i in range(12)]]\n",
    "\n",
    "# Convert time columns to hours\n",
    "X['trend'] = X['trend'] / pd.Timedelta(hours=1)\n",
    "X['time_to_report'] = X['time_to_report'] / pd.Timedelta(hours=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify the continuous features to standardize\n",
    "continuous_features = ['InitialIncurredClaimsCost', 'trend', 'time_to_report', 'MaritalStatus', 'Age',\n",
    "                       'DependentChildren', 'DependentsOther'] + [f'ClaimDescriptionKeyword_{i}' for i in range(12) if i != 5]\n",
    "\n",
    "# Standardize the continuous features\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[continuous_features] = scaler.fit_transform(X_train[continuous_features])\n",
    "X_test_scaled[continuous_features] = scaler.transform(X_test[continuous_features])\n",
    "\n",
    "# Define the parameter grid for alpha values\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 100\n",
      "Out-of-sample Adjusted R-squared: 0.2405233043013283\n",
      "Coefficients in ascending order:\n",
      "ClaimDescriptionKeyword_6: -243.4729289411492\n",
      "ClaimDescriptionKeyword_10: -138.6583898791414\n",
      "ClaimDescriptionKeyword_3: -84.73294361379969\n",
      "ClaimDescriptionKeyword_2: -59.822585681300154\n",
      "DependentsOther: -13.295105780064748\n",
      "trend: -5.608041499221645\n",
      "Gender: 0.0\n",
      "MaritalStatus: -0.0\n",
      "ClaimDescriptionKeyword_0: 0.0\n",
      "ClaimDescriptionKeyword_8: -0.0\n",
      "WeeklyWages: 0.12565365942949136\n",
      "HoursWorkedPerWeek: 0.6236037848038544\n",
      "DependentChildren: 23.007528145111625\n",
      "Age: 109.08009218935064\n",
      "ClaimDescriptionKeyword_5: 124.34577936519285\n",
      "ClaimDescriptionKeyword_4: 207.31084923947577\n",
      "ClaimDescriptionKeyword_9: 235.235652809322\n",
      "ClaimDescriptionKeyword_7: 290.1347005050749\n",
      "time_to_report: 380.576361320848\n",
      "ClaimDescriptionKeyword_11: 412.3010857212126\n",
      "ClaimDescriptionKeyword_1: 775.2162564308585\n",
      "InitialIncurredClaimsCost: 13456.485948999949\n"
     ]
    }
   ],
   "source": [
    "# Create a Lasso model\n",
    "lasso = Lasso()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best alpha value\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "\n",
    "# Train the Lasso model with the best alpha value\n",
    "best_lasso = Lasso(alpha=best_alpha)\n",
    "best_lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the out-of-sample adjusted R-squared\n",
    "out_of_sample_adjusted_r2 = adjusted_r2(y_test, y_pred, X_test.shape[1])\n",
    "print(\"Out-of-sample Adjusted R-squared:\", out_of_sample_adjusted_r2)\n",
    "\n",
    "# Display the coefficients in ascending order of the features\n",
    "coef_dict = dict(zip(X.columns, best_lasso.coef_))\n",
    "sorted_coef = sorted(coef_dict.items(), key=lambda x: x[1])\n",
    "print(\"Coefficients in ascending order:\")\n",
    "for feature, coef in sorted_coef:\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
